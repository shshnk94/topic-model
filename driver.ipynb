{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import os \n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Args:\n",
    "    model: str           #name of the model\n",
    "    mode: str            #mode of the call - train/eval/test\n",
    "    epochs: str          #number of training epochs\n",
    "    topics: str          #number of topics to be trained on\n",
    "    lr: str              #Learning rate\n",
    "    dataset: str         #name of corpus\n",
    "    ckpt_path: str  = '' #checkpoint path (if any)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args(model='etm', mode='train', epochs='2', topics='25', lr='0.005', dataset='20ng')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shashanka-subrahmanya/Study/NLP/topic-model\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n",
      "Training an Embedded Topic Model on 20NG with the following settings: Namespace(anneal_lr=0, batch_size=1000, bow_norm=1, clip=0.0, data_path='data/etm/20ng', dataset='20ng', emb_path='data/20ng_embeddings.txt', emb_size=300, enc_drop=0.0, epochs=2, eval_batch_size=1000, load_from='', log_interval=2, lr=0.005, lr_factor=4.0, mode='train', nonmono=10, num_docs_test=7153, num_docs_train=7524, num_docs_valid=3224, num_topics=25, num_words=10, optimizer='adam', rho_size=300, save_path='./results', seed=0, t_hidden_size=800, tc=0, td=0, theta_act='relu', train_embeddings=1, visualize_every=10, vocab_size=2364, wdecay=1.2e-06)\n",
      "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n",
      "model: ETM(\n",
      "  (t_drop): Dropout(p=0.0, inplace=False)\n",
      "  (theta_act): ReLU()\n",
      "  (rho): Linear(in_features=300, out_features=2364, bias=False)\n",
      "  (alphas): Linear(in_features=300, out_features=25, bias=False)\n",
      "  (q_theta): Sequential(\n",
      "    (0): Linear(in_features=2364, out_features=800, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=800, out_features=800, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (mu_q_theta): Linear(in_features=800, out_features=25, bias=True)\n",
      "  (logsigma_q_theta): Linear(in_features=800, out_features=25, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "Visualizing model quality before training...\n",
      "####################################################################################################\n",
      "Visualize topics...\n",
      "Topic 0: ['cops', 'women', 'pub', 'beat', 'school', 'won', 'md', 'spend', 'concerned']\n",
      "Topic 1: ['search', 'matter', 'sf', 'surrender', 'attention', 'prb', 'finding', 'baltimore', 'sex']\n",
      "Topic 2: ['astronomy', 'motherboard', 'specifically', 'oz', 'vision', 'bu', 'vancouver', 'lived', 'physical']\n",
      "Topic 3: ['mexico', 'technologies', 'session', 'opinions', 'round', 'cup', 'expected', 'feeling', 'examples']\n",
      "Topic 4: ['std', 'develop', 'drop', 'center', 'nature', 'open', 'practice', 'higher', 'labs']\n",
      "Topic 5: ['south', 'doctrine', 'note', 'van', 'immediately', 'fact', 'picture', 'maximum', 'incident']\n",
      "Topic 6: ['angeles', 'widget', 'energy', 'fred', 'expected', 'encrypted', 'results', 'march', 'discovered']\n",
      "Topic 7: ['administration', 'uh', 'drivers', 'services', 'push', 'stuck', 'harvard', 'tx', 'job']\n",
      "Topic 8: ['troops', 'sw', 'recall', 'religion', 'alan', 'copy', 'develop', 'spring', 'determined']\n",
      "Topic 9: ['distance', 'wins', 'ring', 'setup', 'opinions', 'changing', 'solutions', 'answer', 'purdue']\n",
      "Topic 10: ['degree', 'entire', 'multiple', 'association', 'mount', 'require', 'stopped', 'boards', 'steve']\n",
      "Topic 11: ['takes', 'property', 'quick', 'large', 'door', 'brain', 'doctor', 'windows', 'safety']\n",
      "Topic 12: ['media', 'minnesota', 'religions', 'suggested', 'assault', 'cat', 'specifically', 'stable', 'replies']\n",
      "Topic 13: ['army', 'bus', 'condition', 'adams', 'bat', 'larger', 'athos', 'remote', 'basis']\n",
      "Topic 14: ['data', 'cost', 'jack', 'million', 'huh', 'describe', 'scheme', 'acns', 'holes']\n",
      "Topic 15: ['dean', 'hits', 'degree', 'comp', 'concept', 'straight', 'diamond', 'james', 'mouth']\n",
      "Topic 16: ['package', 'church', 'tests', 'flame', 'teach', 'ways', 'recent', 'pages', 'society']\n",
      "Topic 17: ['christopher', 'actual', 'homosexuality', 'leafs', 'earlier', 'relevant', 'passing', 'final', 'steve']\n",
      "Topic 18: ['students', 'released', 'gary', 'explanation', 'pitching', 'straight', 'dark', 'instructions', 'alive']\n",
      "Topic 19: ['school', 'spencer', 'ryan', 'usenet', 'disks', 'uci', 'passed', 'unknown', 'dave']\n",
      "Topic 20: ['games', 'armed', 'design', 'rate', 'davidians', 'slower', 'single', 'arab', 'killing']\n",
      "Topic 21: ['generation', 'moving', 'equipment', 'recently', 'geb', 'bet', 'leave', 'tells', 'previously']\n",
      "Topic 22: ['homosexual', 'figure', 'tapped', 'business', 'ny', 'events', 'magazine', 'keith', 'punishment']\n",
      "Topic 23: ['passes', 'stand', 'units', 'areas', 'lot', 'rules', 'wear', 'strnlght', 'george']\n",
      "Topic 24: ['reader', 'apply', 'tel', 'australia', 'constitution', 'felt', 'vga', 'dealing', 'sleep']\n",
      "####################################################################################################\n",
      "Visualize word embeddings by using output embedding matrix\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "Epoch: 0. batch: 2/8. LR: 0.005. KL_theta: 0.02. Rec_loss: 433.49. NELBO: 433.51\n",
      "Epoch: 0. batch: 4/8. LR: 0.005. KL_theta: 0.01. Rec_loss: 437.97. NELBO: 437.98\n",
      "Epoch: 0. batch: 6/8. LR: 0.005. KL_theta: 0.01. Rec_loss: 438.3. NELBO: 438.31\n",
      "****************************************************************************************************\n",
      "Epoch: 0. batch: 7/8. LR: 0.005. KL_theta: 0.01. Rec_loss: 434.47. NELBO: 434.48\n",
      "****************************************************************************************************\n",
      "Perplexity is:  1987.5677\n",
      "####################################################################################################\n",
      "Visualize topics...\n",
      "Topic 0: ['info', 'university', 'question', 'wrote', 'hope', 'bad', 'card', 'program', 'cs']\n",
      "Topic 1: ['host', 'bad', 'good', 'university', 'put', 'means', 'work', 'system', 'god']\n",
      "Topic 2: ['distribution', 'problem', 'david', 'order', 'university', 'version', 'information', 'cs', 'mail']\n",
      "Topic 3: ['university', 'bad', 'opinions', 'mail', 'power', 'people', 'tin', 'info', 'problem']\n",
      "Topic 4: ['writes', 'good', 'car', 'university', 'bad', 'center', 'key', 'interested', 'high']\n",
      "Topic 5: ['writes', 'fact', 'code', 'host', 'people', 'law', 'cs', 'usa', 'makes']\n",
      "Topic 6: ['information', 'university', 'problem', 'people', 'high', 'nntp', 'good', 'power', 'bad']\n",
      "Topic 7: ['high', 'people', 'gov', 'canada', 'interested', 'university', 'power', 'information', 'center']\n",
      "Topic 8: ['question', 'university', 'writes', 'problem', 'high', 'power', 'bad', 'good', 'hope']\n",
      "Topic 9: ['writes', 'opinions', 'mail', 'question', 'internet', 'nntp', 'understand', 'power', 'system']\n",
      "Topic 10: ['university', 'law', 'bad', 'unix', 'writes', 'people', 'high', 'nntp', 'mail']\n",
      "Topic 11: ['means', 'tin', 'system', 'keywords', 'problem', 'nntp', 'information', 'good', 'university']\n",
      "Topic 12: ['power', 'information', 'key', 'writes', 'gov', 'bad', 'high', 'problem', 'tin']\n",
      "Topic 13: ['interested', 'high', 'distribution', 'university', 'version', 'unix', 'cs', 'internet', 'problem']\n",
      "Topic 14: ['bad', 'canada', 'nntp', 'data', 'people', 'cost', 'law', 'god', 'host']\n",
      "Topic 15: ['key', 'power', 'version', 'university', 'keywords', 'interested', 'mail', 'information', 'andrew']\n",
      "Topic 16: ['university', 'fact', 'canada', 'nntp', 'law', 'card', 'writes', 'box', 'internet']\n",
      "Topic 17: ['canada', 'bad', 'hope', 'idea', 'good', 'run', 'problem', 'years', 'box']\n",
      "Topic 18: ['university', 'nntp', 'information', 'box', 'power', 'email', 'remember', 'world', 'cs']\n",
      "Topic 19: ['question', 'people', 'nntp', 'means', 'case', 'time', 'writes', 'put', 'law']\n",
      "Topic 20: ['university', 'nntp', 'question', 'interested', 'cs', 'distribution', 'tin', 'info', 'law']\n",
      "Topic 21: ['nntp', 'university', 'high', 'interested', 'power', 'internet', 'information', 'version', 'system']\n",
      "Topic 22: ['writes', 'distribution', 'high', 'nntp', 'university', 'good', 'god', 'interested', 'jesus']\n",
      "Topic 23: ['university', 'host', 'bad', 'high', 'mail', 'information', 'problem', 'writes', 'question']\n",
      "Topic 24: ['writes', 'read', 'high', 'program', 'question', 'find', 'hope', 'system', 'internet']\n",
      "####################################################################################################\n",
      "Visualize word embeddings by using output embedding matrix\n",
      "####################################################################################################\n",
      "Epoch: 1. batch: 2/8. LR: 0.005. KL_theta: 0.01. Rec_loss: 421.59. NELBO: 421.6\n",
      "Epoch: 1. batch: 4/8. LR: 0.005. KL_theta: 0.01. Rec_loss: 423.9. NELBO: 423.91\n",
      "Epoch: 1. batch: 6/8. LR: 0.005. KL_theta: 0.01. Rec_loss: 422.87. NELBO: 422.88\n",
      "****************************************************************************************************\n",
      "Epoch: 1. batch: 7/8. LR: 0.005. KL_theta: 0.01. Rec_loss: 420.33. NELBO: 420.33\n",
      "****************************************************************************************************\n",
      "Perplexity is:  1816.908\n",
      "Perplexity is:  1816.908\n"
     ]
    }
   ],
   "source": [
    "#python main.py --mode train --dataset 20ng --data_path data/20ng --num_topics 50 --train_embeddings 1 --epochs 1000\n",
    "data_path = 'data/' + args.model + '/' + args.dataset\n",
    "train_embeddings = '1'\n",
    "current_folder = '/Users/shashanka-subrahmanya/Study/NLP/topic-model'\n",
    "cmd = ('python etm/main.py --mode ' + args.mode + \n",
    "          ' --dataset ' + args.dataset +\n",
    "          ' --data_path ' + data_path +\n",
    "          ' --num_topics ' + args.topics +\n",
    "          ' --train_embeddings ' + train_embeddings +\n",
    "          ' --epochs ' + args.epochs)\n",
    "            \n",
    "from subprocess import Popen, PIPE, CalledProcessError\n",
    "\n",
    "with Popen(cmd, stdout=PIPE, bufsize=1, universal_newlines=True, shell=True, cwd=current_folder) as p:\n",
    "    for line in p.stdout:\n",
    "        print(line, end='') # process line here\n",
    "\n",
    "if p.returncode != 0:\n",
    "    print(p.__dict__)\n",
    "    raise CalledProcessError(p.returncode, p.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'data/' + args.model + '/' + args.dataset\n",
    "save_path = 'results/' + args.model + '/' + args.dataset\n",
    "\n",
    "train_embeddings = '1'\n",
    "\n",
    "os.system('python etm/main.py --mode ' + args.mode + \n",
    "          ' --dataset ' + args.dataset +\n",
    "          ' --data_path ' + data_path +\n",
    "          ' --save_path ' + save_path +\n",
    "          ' --num_topics ' + args.topics +\n",
    "          ' --train_embeddings ' + train_embeddings +\n",
    "          ' --epochs ' + args.epochs +\n",
    "          ' --lr ' + args.lr +\n",
    "          ' --tc ' + '1' + \n",
    "          ' --td ' + '1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.ckpt_path = 'results/etm/20ng/etm_20ng_K_25_Htheta_800_Optim_adam_Clip_0.0_ThetaAct_relu_Lr_0.005_Bsz_1000_RhoSize_300_trainEmbeddings_1'\n",
    "args.mode = 'test'\n",
    "\n",
    "os.system('python ETM/main.py --mode ' + args.mode + \n",
    "          ' --dataset ' + args.dataset +\n",
    "          ' --data_path ' + data_path +\n",
    "          ' --save_path ' + save_path +\n",
    "          ' --num_topics ' + args.topics +\n",
    "          ' --train_embeddings ' + train_embeddings +\n",
    "          ' --lr ' + args.lr +\n",
    "          ' --tc ' + '1' + \n",
    "          ' --td ' + '1' +\n",
    "          ' --load_from ' + args.ckpt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c71149e65086a89a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c71149e65086a89a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6009;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tb_logs = save_path + '/logs'\n",
    "%tensorboard --logdir $tb_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NVDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args(model='nvdm', mode='train', epochs='25', topics='25', lr='5e-5', dataset='20ng')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'data/' + args.model + '/' + args.dataset\n",
    "save_path = 'results/' + args.model + '/' + args.dataset\n",
    "\n",
    "vocab_size = '5430' if args.dataset == '20ng' else '20881'\n",
    "    \n",
    "os.system('python nvdm/nvdm.py --data_dir ' + data_path +\n",
    "          ' --n_topic ' + args.topics +\n",
    "          ' --epochs ' + args.epochs +\n",
    "          ' --vocab_size ' + vocab_size +\n",
    "          ' --learning_rate ' + args.lr + \n",
    "          ' --save_path ' + save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = 'True'\n",
    "\n",
    "os.system('python nvdm/nvdm.py --data_dir ' + data_path +\n",
    "          ' --test ' + test +\n",
    "          ' --n_topic ' + args.topics +\n",
    "          ' --epochs ' + args.epochs +\n",
    "          ' --vocab_size ' + vocab_size +\n",
    "          ' --learning_rate ' + args.lr +\n",
    "          ' --save_path ' + save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_logs = save_path + '/logs'\n",
    "%tensorboard --logdir $tb_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProdLDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args(model='prodlda', mode='train', epochs='25', topics='25', lr='0.002', dataset='20ng')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'data/' + args.model + '/' + args.dataset\n",
    "save_path = 'results/' + args.model + '/' + args.dataset\n",
    "\n",
    "os.system('CUDA_VISIBLE_DEVICES=0 python prodlda/run.py -m prodlda' +\n",
    "          ' -f 100' + \n",
    "          ' -s 100' +\n",
    "          ' -t ' + args.topics +\n",
    "          ' -b 200' + \n",
    "          ' -r ' + args.lr +\n",
    "          ' -e ' + args.epochs +\n",
    "          ' --data_path ' + data_path + \n",
    "          ' --save_path ' + save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "junk",
   "language": "python",
   "name": "junk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
